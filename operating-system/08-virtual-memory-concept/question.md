## 가상 메모리 질문

<details>
    <summary>
        <strong style="font-size: 20px">가상메모리 개념이 등장한 이유는 무엇인가요?</strong>
    </summary>
    가상메모리는 컴퓨터 시스템의 물리적 메모리 한계를 극복하기 위해 등장했습니다. 초기 컴퓨터 시스템에서는 프로그램의 크기가 물리적 메모리 용량을 초과할 수 없었습니다. 이로 인해 개발자들은 항상 제한된 메모리 공간 내에서 프로그램을 작성해야 했고, 여러 프로그램을 동시에 실행하는 것도 어려웠습니다. 가상메모리는 이러한 제약을 해결하기 위해 물리적 메모리와 보조 저장장치(주로 하드 디스크)를 함께 활용하여 프로그램에게 더 큰 메모리 공간을 제공합니다.
    <br/>
    <details>
        <summary>
            <strong>가상 메모리와 물리적 메모리의 주소 변환 과정에 대해 설명해주세요.</strong>
        </summary>
        프로세스가 가상 주소를 참조하면, 메모리 관리 유닛 MMU가 이를 물리적 주소로 변환합니다. 가상 주소는 페이지 번호와 오프셋으로 구성되며, 페이지 테이블을 통해 해당 페이지가 위치한 물리적 메모리의 프레임 번호를 찾습니다. 이 프레임 번호와 오프셋을 결합하여 최종 물리적 주소가 결정됩니다. 주소 변환 과정의 효율성을 높이기 위해 TLB라는 특수한 캐시가 사용되어 최근 변환된 페이지 정보를 저장합니다.
        만약 참조하려는 페이지가 물리적 메모리에 없다면 페이지 폴트가 발생합니다. 이때 운영체제는 해당 페이지를 디스크에서 메모리로 로드해야 하며 이 과정에서 메모리가 부족하면 기존의 페이지를 디스크로 다시 스왑아웃합니다. 
        <br/>
    </details>
    <details>
        <summary>
            <strong>가상 메모리가 없는 시스템과 비교한다면 성능 측면에서 무엇이 다를까요?</strong>
        </summary>
        가상 메모리가 없는 시스템은 주소 변환 오버헤드가 없어 메모리 접근 속도가 빠릅니다. 하지만 물리적 메모리 크기에 제한되어 대규모 프로그램 실행이 어렵고, 메모리 단편화 문제가 심각해질 수 있으며 프로세스 간 메모리 보호 메커니즘이 제한적입니다. 
        가상 메모리 시스템은 주소 변환 과정과 페이지 폴트 처리로 인한 지연이 발생할 수 있습니다. 특히 페이지 폴트가 자주 발생하는 경우 성능이 크게 저하 될 수 있습니다. 대신 물리적 메모리 크기보다 큰 프로그램을 실행할 수 있고, 다중 프로그래밍 환경에서 메모리 사용 효율성이 좋으며, 프로그래머가 메모리 관리에 신경쓰지 않고 개발할 수 있습니다.
        <br/>
    </details>
    <details>
        <summary>
            <strong>현대 운영체제에서 가상 메모리를 관리하기 위해 사용하는 최적화 기법에는 무엇이 있을까요?</strong>
        </summary>
        <ul>
          <li>페이징 : 가상 메모리를 고정된 크기의 페이지로 나누어 관리하여 외부 단편화를 줄이고 메모리 할당을 효율적으로 수행</li>
          <li>선반입 : 예측을 통해 앞으로 필요할 것으로 예상되는 페이지를 미리 메모리로 가져옴</li>
          <li>지역성 활용 : 최근에 참조된 메모리와 참조된 메모리 주변의 메모리는 곧 참조될 가능성이 높음</li>
          <li>멀티레벨 페이지 테이블 : 페이지 테이블을 계층적으로 구성하여 메모리 사용량을 줄임</li>
          <li>TLB : 자주 사용되는 페이지 테이블 항목을 캐싱하여 메모리 접근 속도 향상</li>
          <li>메모리 압축 : 사용되지 않는 페이지를 디스크로 옮기기 전에 압축하여 메모리에 유지</li>
          <li>요구 페이징 : 실제로 필요할 때만 페이지를 메모리로 가져옴</li>
          <li>세그멘테이션 : 메모리를 논리적 단위인 세그먼트로 관리</li>
          <li>대용량 페이지 : 특정 애플리케이션을 위해 더 큰 크기의 페이지를 사용하여 TLB를 높임</li>
        </ul>
        <br/>
    </details>
    <details>
        <summary>
            <strong>모바일 기기와 같은 제한된 리소스 환경에서 가상 메모리 구현은 어떻게 구현될까요?</strong>
        </summary>
        모바일 기기는 데스크톱과 달리 플래시 메모리를 활용합니다. 플래시 메모리의 제한된 쓰기 수명과 블록 단위 소거 특성을 고려하여 알고리즘이 설계됩니다. 또한 LRU나 FIFO와 같은 페이지 교체 알고리즘이 배터리 소모와 성능을 고려하여 수정되고 페이지를 디스크로 스왑하기 전에 압축하여 I/O 부하를 줄입니다. 성능 뿐만 아니라 배터리도 중요하게 고려해야 하는데, 사용자 패턴을 분석하여 필요할 것으로 예상되는 페이지를 미리 로드하고, 모든 페이지를 무조건 스왑하지 않고 중요도와 접근 빈도에 따라 선별적으로 스왑합니다.
        <br/>
    </details>
    <br/>
</details>
<details>
    <summary>
        <strong style="font-size: 20px">페이징과 세그먼테이션의 차이점은 무엇인가요?</strong>
    </summary>
    페이징은 물리적 관점에서 메모리를 동일한 크기의 블록으로 나누는 반면, 세그멘테이션은 논리적 관점에서 프로그램의 구조에 따라 다양한 크기의 단위로 나눕니다. 페이징에서는 프로그램이 고정 크기 블록인 페이지로 나뉘어집니다. 각 페이지는 프레임이라 불리는 물리 메모리의 블록에 로드됩니다. 이 방법은 메모리 할당이 간단하지만, 실제 프로그램의 구조와는 무관하게 분할되므로 마지막 페이지가 채워지지 않는 내부 단편화 문제가 발생합니다. 
    세그멘테이션은 프로그램을 코드, 스택, 데이터와 같은 논리적 단위로 나눕니다. 각 세그먼트는 크기가 다영하며 프로그램의 구조를 직접 반영합니다. 이는 내부 단편화를 방지하지만 다양한 메모리 크기를 가진 블록을 할당하고 관리해야 하므로 외부 단편화 문제가 발생할 수 있습니다.
    페이징과 세그먼테이션은 주소 변환 방식에서도 차이를 보입니다. 페이징 시스템에서 가상 주소는 페이지 번호와 페이지 내 오프셋으로 구성됩니다. 페이지 테이블을 통해 페이지 번호를 실제 물리 메모리의 프레임 번호로 변환한 후, 오프셋을 그대로 사용하여 최종 물리 주소를 얻습니다.
    세그먼테이션에서는 가상 주소가 세그먼트 번호(또는 이름)와 세그먼트 내 오프셋으로 구성됩니다. 세그먼트 테이블은 각 세그먼트의 기준 주소와 길이 정보를 담고 있어, 이를 통해 가상 주소를 물리 주소로 변환합니다. 이 과정에서 주소 변환뿐 아니라 세그먼트 길이를 초과하는 접근에 대한 검사도 이루어집니다.
    <br/>
    <details>
        <summary>
            <strong>페이징과 세그먼테이션을 결합한다면 어떻게 만들 수 있을까요?</strong>
        </summary>
        프로그램을 먼저 논리적 세그먼트로 나눈 후, 각 세그먼트를 다시 고정 크기의 페이지로 나눕니다.
        가상 주소는 세그먼트 번호, 페이지 번호, 오프셋으로 구성됩니다. 세그먼트 테이블은 각 세그먼트에 대한 페이지 테이블의 위치를 가리키고, 이 페이지 테이블을 통해 페이지 번호를 물리적 프레임 번호로 변환합니다.
        이러한 접근법은 세그먼테이션의 논리적 구조 반영과 보호/공유 이점을 유지하면서도, 페이징의 효율적인 메모리 할당과 외부 단편화 방지 이점을 활용합니다. 실제로 Intel x86 아키텍처에서는 이러한 페이지드 세그먼테이션 방식을 초기에 채택했으며, 현대 운영체제들은 이를 발전시켜 다양한 형태로 구현하고 있습니다.
        <br/>
    </details>
</details>
<details>
    <summary>
        <strong style="font-size: 20px">가상 메모리에서 페이지 테이블의 역할과 구조에 대해 설명해주세요.</strong>
    </summary>
    페이지 테이블은 가상 주고(프로세스가 참조하는 주소)를 물리 주소(실제 메모리 주소)로 변환하고, 각 페이지에 대한 접근 권한을 관리하여 무단 접근을 방지하며, 페이지가 현재 메모리에 존재하는지, 수정되었는지 등의 상태 정보를 유지합니다.
    페이지 테이블은 배열 형태로 구현되며 각 엔트리(페이지 테이블 항목)에는 
    <ul>
      <li>프레임 번호 : 가상 페이지가 매핑된 물리적 프레임 번호</li>
      <li>유효 비트 : 페이지가 현재 물리 메모리에 있는지 디스크에 있는지 여부</li>
      <li>더티 비트 : 페이지가 메모리에 로드된 이후 수정되었는지 여부</li>
      <li>참조 비트 : 페이지가 최근에 접근되었는지 여부</li>
      <li>보호 비트 : 페이지에 대한 읽기/쓰기/실행 권한 정보</li>
    </ul>
    과 같은 정보를 포함합니다.
    <br/>
    <details>
        <summary>
            <strong>페이지 테이블에 원하는 데이터가 없다면 어떻게 될까요?</strong>
        </summary>
        페이지 폴트가 발생합니다. 
        <ul>
          <li>1. 프로세스가 메모리에 없는 페이지에 접근하면 MMU가 이를 감지하고 CPU에 예외를 발생시킴</li>
          <li>2. CPU는 현재 명령어의 실행을 중단하고 운영체제의 페이지 폴트 핸들러로 제어를 넘김</li>
          <li>3. 운영체제가 페이지 폴트의 원인 분석</li>
          <li>4. 빈 프레임을 확인하거나 페이지 교체 알고리즘으로 페이지 선택</li>
          <li>5. 요청된 페이지를 디스크에서 메모리로 로드하고 페이지 테이블 업데이트</li>
          <li>6. 페이지가 메모리에 로드되면 운영체제는 프로세스 실행 재개</li>
        </ul>
        페이지 폴트는 디스크 I/O를 포함하기 때문에 상당한 시간이 소요되므로 발생을 최소화해야 합니다. 이를 위해 다양한 페이지 교체 알고리즘과 최적화 기법이 개발되었습니다.
        <br/>
    </details>
</details>
<details>
    <summary>
        <strong style="font-size: 20px">페이지 폴트란 무엇일까요?</strong>
    </summary>
    가상 메모리 시스템에서 프로세스가 접근하려는 페이지가 현재 RAM에 없을 때 발생하는 예외 상황
    <br/>
    <details>
        <summary>
            <strong>페이지 폴트가 발생하면 운영체제는 어떻게 처리할까요?</strong>
        </summary>
        <ul>
          <li>1. 프로세스가 메모리에 없는 페이지에 접근하면 MMU가 이를 감지하고 CPU에 예외를 발생시킴</li>
          <li>2. CPU는 현재 명령어의 실행을 중단하고 운영체제의 페이지 폴트 핸들러로 제어를 넘김</li>
          <li>3. 운영체제가 페이지 폴트의 원인 분석</li>
          <li>4. 빈 프레임을 확인하거나 페이지 교체 알고리즘으로 페이지 선택</li>
          <li>5. 요청된 페이지를 디스크에서 메모리로 로드하고 페이지 테이블 업데이트</li>
          <li>6. 페이지가 메모리에 로드되면 운영체제는 프로세스 실행 재개</li>
        </ul>
        <br/>
    </details>
    <details>
        <summary>
            <strong>페이지 폴트 빈도를 줄이기 위한 방법에는 어떤 것이 있을까요? 각 방법의 장단점은 무엇이 있을까요?</strong>
        </summary>
        <ul>
          <li>1. RAM 증설</li>
          <ul>
            <li>직접적으로 페이지 폴트 감소</li>
            <li>비용 증가, 물리적 제약(최대 설치 가능 메모리 한계), 전력 소모 증가</li>
          </ul>
          <li>2. 효율적인 페이지 교체 알고리즘 사용</li>
          <ul>
            <li>중요한 페이지를 메모리에 유지하여 폴트 감소</li>
            <li>이상적인 알고리즘은 미래 접근 패턴을 알아야 하므로 실제로 구현 불가능, 모근 워크로드에 최적인 단일 알고리즘은 존재할 수 없음</li>
          </ul>
          <li>3. 페이지 선반입</li>
          <ul>
            <li>예상되는 페이지를 미리 메모리에 로드하여 폴트 예방</li>
            <li>예측이 잘못되면 오히려 낭비, 추가적인 대역폭 사용</li>
          </ul>
          <li>4. 프로세스 작업 세트 관리</li>
          <ul>
            <li>프로세스가 현재 필요로 하는 페이지 집합에 집중</li>
            <li>작업 세트 크기 결정이 어렵고 동적 환경에서 지속적인 모니터링 필요</li>
          </ul>
          <li>5. 메모리 압축 기술 활용</li>
          <ul>
            <li>디스크 I/O 감소</li>
            <li>압축/해제 시 CPU 오버헤드, 캐시 활용도에 부정적 영향 가능성</li>
          </ul>
          <li>6. 프로그램 최적화</li>
          <ul>
            <li>근본적인 문제 해결 접근법</li>
            <li>개발 시간과 비용</li>
          </ul>
          <li>7. 페이지 컬러링 : 물리적 메모리 페이지를 프로세서의 캐시 구조에 맞게 할당하여 캐시 성능 향상</li>
          <ul>
            <li>캐시 충돌 감소로 캐시 효율성 향상, 메모리 접근 지연 시간 감소</li>
            <li>구현이 복잡하고 시스템 유연성을 제한하여 모든 하드웨어에서 효과적이진 않음</li>
          </ul>
        </ul>
        <br/>
    </details>
</details>
