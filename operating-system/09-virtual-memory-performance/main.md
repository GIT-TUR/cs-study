# 가상 메모리와 관련한 주요 개념 및 성능 최적화

## 1. 가상 메모리 성능의 주요 요소

### 1.1 페이지 폴트 처리 시간

- **정의**: CPU가 필요한 메모리 페이지가 물리 메모리에 없을 때, 이를 보충(디스크에서 읽어 들임)하는 데 걸리는 시간.
- **영향 요인**:
  - 디스크 I/O 속도
  - 페이지 교체 알고리즘의 효율성
  - 운영체제의 인터럽트 처리 및 스케줄링 오버헤드

### 1.2 유효 접근 시간 (Effective Access Time, EAT)

- **정의**: 정상적인 메모리 접근 시간과 페이지 폴트 발생 시의 추가 지연을 고려한 평균 메모리 접근 시간.
- **계산 방식**:
  - EAT = (1 - p) _ 메모리 접근 시간 + p _ (페이지 폴트 처리 시간 + 메모리 접근 시간)
  - 여기서 p는 페이지 폴트 발생 확률.

### 1.3 페이지 폴트 빈도

- **의미**: 단위 시간당 발생하는 페이지 폴트의 수.
- **영향**: 페이지 폴트 빈도가 높으면, 디스크 I/O 오버헤드가 증가하여 전체 성능이 저하됨.
- **최적화**: 작업 세트(Working Set) 모델이나 PFF(Page Fault Frequency) 기법을 통해 적절한 프레임 할당을 결정.

### 1.4 메모리 사용률

- **정의**: 전체 물리 메모리 중 실제로 사용 중인 비율.
- **영향**:
  - 메모리 과부하 시 스레싱(Thrashing) 발생 위험 증가.
  - 적절한 메모리 할당 정책과 페이지 교체 알고리즘을 통해 최적화 필요.

---

## 2. 페이지 교체 알고리즘과 성능

페이지 교체 알고리즘은 제한된 물리 메모리 내에서 어떤 페이지를 제거하고 새로운 페이지를 로드할지 결정하는 전략입니다.

### 2.1 최적(Optimal) 알고리즘

- **개념**: 앞으로 사용되지 않을 페이지를 제거하는 방식으로, 이론적으로 최소 페이지 폴트 수를 보장함.
- **한계**: 미래의 메모리 접근 패턴을 미리 알 수 없으므로, 실제 구현은 불가능.

#### 2.1.1 벨라디의 최적 알고리즘

- **내용**:
  - 미리 전체 참조 문자열(메모리 접근 순서)을 알고 있다고 가정하고, 가장 오래 사용되지 않을 페이지를 교체.
  - 벨라디(Belady)가 제시한 이론적 모델로, 최적 알고리즘의 기준 역할.

#### 2.1.2 실제 구현의 한계

- **문제점**:
  - 미래 참조 정보를 알 수 없으므로 실제 시스템에서는 근사 알고리즘(LRU, Clock 등)으로 대체.
  - 계산 비용과 예측 오차로 인해 최적 알고리즘은 이론적인 비교 대상에 불과.

### 2.2 FIFO (First-In-First-Out)

- **동작 방식**: 가장 먼저 메모리에 들어온 페이지를 먼저 교체.
- **특징**: 구현이 간단하지만, 최근에 많이 사용되는 페이지를 버리는 단점이 있음.

#### 2.2.1 동작 방식과 특징

- **장점**: 구현 및 관리가 단순함.
- **단점**: 최신 사용 패턴을 반영하지 못해 성능 저하 유발 가능.

#### 2.2.2 FIFO 이상 현상 (Anomaly)

- **내용**: 페이지 수를 늘렸음에도 불구하고 페이지 폴트 수가 증가하는 현상.
- **의미**: 더 많은 프레임이 항상 더 좋은 성능을 보장하지 않는다는 점을 보여줌.

### 2.3 LRU (Least Recently Used)

- **동작 원리**: 가장 오랫동안 사용되지 않은 페이지를 교체 대상으로 선택.
- **특징**: 시간적 지역성을 활용하여, 최근에 사용된 페이지가 앞으로도 사용될 가능성이 높다는 가정.

#### 2.3.1 구현 방식

- **구현 예**: 링크드 리스트, 해시맵과 결합한 자료구조, 또는 시간 스탬프를 이용.
- **문제점**: 정확한 LRU 구현은 오버헤드가 크기 때문에 근사 알고리즘(예: Clock 알고리즘)이 많이 사용됨.

#### 2.3.2 성능 특성

- **장점**: 실제 사용 패턴에 근접하여 효과적인 페이지 교체 가능.
- **단점**: 구현 복잡도와 유지 비용 증가.

#### 2.3.4 하드웨어 지원 필요성

- **설명**:
  - CPU나 메모리 관리 유닛(MMU)이 LRU 관련 정보를 제공하면 소프트웨어 구현 부담이 줄어듦.
  - 일부 시스템에서는 하드웨어 기반 캐시 관리 기법을 활용하기도 함.

### 2.4 Clock 알고리즘

- **개념**: 원형 큐를 사용하여 LRU의 근사치를 제공하는 알고리즘.
- **특징**: 각 페이지에 ‘참조 비트’를 할당하여, 참조가 있었는지 여부를 표시하고, 이를 기준으로 교체 대상을 결정.

#### 2.4.1 Second Chance 알고리즘

- **동작 원리**: FIFO 기반이지만, 페이지의 참조 비트가 설정되어 있으면 한 번 더 기회를 주어 다시 큐의 끝으로 보냄.
- **효과**: 단순 FIFO보다 LRU에 가까운 결과를 얻을 수 있음.

#### 2.4.2 개선된 Clock 알고리즘

- **내용**:
  - 여러 단계의 참조 비트나 추가 정보를 이용해 더욱 정밀하게 교체 대상을 결정.
  - 성능과 구현 복잡성 사이의 균형을 맞춤.

### 2.5 각 알고리즘의 성능 비교

- **최적(Optimal)**: 이론상 최소 페이지 폴트, 그러나 구현 불가능.
- **FIFO**: 구현이 단순하나, 이상 현상으로 인한 성능 저하 가능.
- **LRU**: 지역성에 기반한 효과적인 교체, 하지만 구현 비용이 높음.
- **Clock/Second Chance**: LRU의 근사치로, 비용과 성능의 타협점을 제공.

---

## 3. TLB (Translation Lookaside Buffer)

TLB는 가상 주소를 물리 주소로 변환하는 과정을 가속화하기 위해 사용되는 캐시 메모리입니다.

### 3.1 TLB의 구조와 동작 원리

- **구조**:
  - 제한된 수의 엔트리를 가진 고속 캐시로, 각 엔트리는 가상 페이지 번호와 대응하는 물리 페이지 번호를 저장.
- **동작**:
  - 가상 주소 참조 시 먼저 TLB를 검색하여 매핑 정보를 찾고, 없을 경우 페이지 테이블을 조회.

### 3.2 TLB Hit Ratio의 중요성

- **TLB Hit**: TLB에서 매핑 정보를 찾았을 때, 매우 빠른 주소 변환이 가능.
- **영향**:
  - TLB Hit Ratio가 높을수록 평균 메모리 접근 시간이 단축되어 시스템 성능이 향상됨.

### 3.3 TLB 관리 정책

#### 3.3.1 TLB 교체 알고리즘

- **유형**:
  - LRU, FIFO, 또는 단순 임의 선택(random replacement) 방식 등.
- **목표**: 최근 사용 빈도가 높은 페이지의 정보를 유지하여 높은 Hit Ratio 달성.

#### 3.3.2 TLB 일관성 유지

- **문제**:
  - 페이지 테이블의 변화(예, 페이지 교체, 권한 변경)가 있을 때 TLB의 엔트리와 불일치 발생.
- **해결**:
  - TLB 플러시(전체 또는 일부), 또는 소프트웨어와 하드웨어의 협력에 의한 일관성 유지.

### 3.4 TLB 성능 최적화 기법

#### 3.4.1 Multi-level TLB

- **개념**:
  - 여러 계층의 TLB를 사용하여, 첫 번째 계층은 매우 빠르지만 용량이 작고, 두 번째 계층은 다소 느리지만 용량이 큰 구조.
- **장점**:
  - 높은 Hit Ratio와 확장성을 동시에 달성할 수 있음.

#### 3.4.2 TLB 예측

- **방법**:
  - 과거의 주소 변환 패턴을 분석하여, 미래의 접근을 미리 예측하고 TLB에 미리 로드하는 기법.
- **효과**:
  - 예측이 성공할 경우 TLB Miss를 줄여 전체 성능을 향상.

---

## 4. 스레싱 (Thrashing)

스레싱은 과도한 페이지 폴트와 빈번한 페이지 교체로 인해 시스템이 실제 작업보다는 페이지 교체에 대부분의 시간을 소비하는 상태를 의미합니다.

### 4.1 스레싱의 정의와 발생 원인

- **정의**:
  - 시스템의 메모리 자원이 부족해, 많은 프로세스가 동시에 페이지 교체를 발생시키는 상태.
- **원인**:
  - 과도한 프로세스 동시 실행
  - 잘못된 메모리 할당 정책
  - 페이지 크기나 작업 집합의 부적절한 관리

### 4.2 스레싱이 시스템 성능에 미치는 영향

- **영향**:
  - CPU가 실제 연산보다 페이지 교체에 소모되는 시간 증가
  - 전체 시스템 응답 시간 및 처리량 감소

### 4.3 스레싱 방지 기법

#### 4.3.1 작업 세트 (Working Set) 모델

- **개념**:
  - 각 프로세스가 일정 시간 동안 참조한 페이지 집합을 기반으로, 필요한 메모리 프레임 수를 결정.
- **목표**:
  - 프로세스에 필요한 최소 메모리 할당량을 보장하여 스레싱 방지.

#### 4.3.2 페이지 폴트 빈도 (PFF) 기법

- **개념**:
  - 페이지 폴트 빈도를 모니터링하여, 일정 기준 이상일 경우 프로세스의 메모리 할당을 조정.
- **효과**:
  - 페이지 폴트가 급증하면, 해당 프로세스의 작업 세트를 확대하거나 스케줄링 우선순위를 낮추어 스레싱을 완화.

#### 4.3.3 프로세스 우선순위 조정

- **방법**:
  - 메모리 집약적인 프로세스의 우선순위를 낮추거나, 메모리 자원을 재분배하여 스레싱 위험을 감소시킴.

### 4.4 메모리 할당 정책

#### 4.4.1 전역 교체와 지역 교체

- **전역 교체 (Global Replacement)**:
  - 모든 프로세스 간에 프레임을 공유하며, 전체 시스템에서 가장 오래된 페이지를 교체.
- **지역 교체 (Local Replacement)**:
  - 각 프로세스별로 할당된 프레임 내에서만 페이지 교체를 수행.
- **비교**:
  - 전역 교체는 자원의 효율적 사용이 가능하지만, 한 프로세스의 부하가 전체에 영향을 줄 수 있음.
  - 지역 교체는 프로세스 간 격리 효과가 있으나, 일부 프로세스가 부족한 프레임으로 성능 저하가 발생할 수 있음.

#### 4.4.2 프레임 할당 알고리즘

- **목표**:
  - 각 프로세스에 적절한 프레임 수를 할당하여, 작업 세트를 만족시키면서도 스레싱을 방지.
- **전략**:
  - 동적 조정, 우선순위 기반 재분배 등 다양한 기법이 사용됨.

---

## 5. 가상 메모리 성능 최적화 기법

### 5.1 선페이징 (Prepaging)

- **개념**:
  - 프로세스 실행 전에 예상되는 페이지들을 미리 로드하여, 초기 페이지 폴트 발생을 줄이는 기법.
- **효과**:
  - 프로그램 시작 시의 지연 감소 및 성능 향상.

### 5.2 페이지 크기 최적화

- **고려 사항**:
  - 너무 작은 페이지는 페이지 테이블의 오버헤드를 증가시키고, 너무 큰 페이지는 내부 단편화를 유발.
- **목표**:
  - 시스템 특성과 애플리케이션의 메모리 접근 패턴을 고려하여 최적의 페이지 크기 결정.

### 5.3 프로그램 지역성 활용

- **지역성의 종류**:
  - **시간적 지역성**: 최근 사용한 페이지가 가까운 미래에도 사용될 확률이 높음.
  - **공간적 지역성**: 인접한 메모리 주소에 있는 데이터도 함께 사용될 가능성이 높음.
- **최적화**:
  - 캐시와 페이지 프리페칭 기법을 활용하여 지역성을 극대화.

### 5.4 페이지 버퍼링과 캐싱

- **페이지 버퍼링**:
  - 페이지 교체 시, 바로 폐기하지 않고 임시 버퍼에 보관해 재사용 가능성을 높임.
- **캐싱**:
  - 자주 사용되는 페이지나 데이터는 별도의 캐시 메모리에 저장하여 접근 시간을 단축.

---

## 6. 성능 측정과 모니터링

### 6.1 주요 성능 지표

- **페이지 폴트율**: 전체 메모리 접근 중 페이지 폴트가 발생한 비율.
- **TLB Hit Ratio**: TLB를 통한 주소 변환 성공률.
- **유효 접근 시간 (EAT)**: 평균 메모리 접근 시간.
- **메모리 사용률 및 작업 세트 크기**: 각 프로세스가 실제 사용하는 메모리 비율.

### 6.2 모니터링 도구

- **시스템 모니터링**: top, vmstat, sar 등 OS 제공 도구.
- **프로파일링 툴**: 성능 분석 및 페이지 교체, TLB 미스 등을 기록하는 전용 도구.
- **하드웨어 성능 카운터**: CPU의 성능 모니터링 유닛(PMU)을 활용해 캐시, TLB 관련 정보를 수집.

### 6.3 성능 분석 방법론

- **측정**:
  - 실제 시스템에서 페이지 폴트, TLB 히트율, 메모리 접근 시간 등을 측정.
- **분석**:
  - 수집된 데이터를 기반으로 병목 현상을 파악하고, 최적화 기법(예: 선페이징, 작업 세트 모델 적용)을 적용.
- **모델링**:
  - 이론적 모델(EAT 계산식, 페이지 폴트 확률 등)을 활용하여 최적 메모리 할당 전략을 도출.
